{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:10:37.944103Z",
     "iopub.status.busy": "2024-06-14T13:10:37.943331Z",
     "iopub.status.idle": "2024-06-14T13:11:07.613533Z",
     "shell.execute_reply": "2024-06-14T13:11:07.612520Z",
     "shell.execute_reply.started": "2024-06-14T13:10:37.944071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyyaml==5.1\n",
      "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[34 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-r96n4ehp/pyyaml_bb8f4320c6cd404984d26db62bde0084/setup.py\", line 291, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 963, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 321, in run\n",
      "  \u001b[31m   \u001b[0m     self.find_sources()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 329, in find_sources\n",
      "  \u001b[31m   \u001b[0m     mm.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 551, in run\n",
      "  \u001b[31m   \u001b[0m     self.add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 589, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/sdist.py\", line 112, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     super().add_defaults()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 251, in add_defaults\n",
      "  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 336, in _add_defaults_ext\n",
      "  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-r96n4ehp/pyyaml_bb8f4320c6cd404984d26db62bde0084/setup.py\", line 199, in get_source_files\n",
      "  \u001b[31m   \u001b[0m     self.cython_sources(ext.sources, ext)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n",
      "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
      "  \u001b[31m   \u001b[0m AttributeError: cython_sources\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "Cloning into 'detectron2'...\n",
      "remote: Enumerating objects: 15730, done.\u001b[K\n",
      "remote: Counting objects: 100% (453/453), done.\u001b[K\n",
      "remote: Compressing objects: 100% (331/331), done.\u001b[K\n",
      "remote: Total 15730 (delta 206), reused 299 (delta 113), pack-reused 15277\u001b[K\n",
      "Receiving objects: 100% (15730/15730), 6.51 MiB | 28.14 MiB/s, done.\n",
      "Resolving deltas: 100% (11321/11321), done.\n",
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (9.5.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Collecting yacs>=0.1.8\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n",
      "Collecting omegaconf<2.4,>=2.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting black\n",
      "  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (21.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs>=0.1.8) (6.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.59.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.3)\n",
      "Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black) (1.0.0)\n",
      "Collecting packaging\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pathspec>=0.9.0 (from black)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black) (3.11.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black) (4.9.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
      "  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=7c962a113942638a373b4192c1840955c63c7f238901d5920c46f835e7657a0f\n",
      "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=522363f1c96dbf6ab5bb05a660a5134cbb0a504957828f7710ba3f03a42d784e\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built fvcore antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.4.1 requires cubinlinker, which is not installed.\n",
      "cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.4.1 requires ptxcompiler, which is not installed.\n",
      "cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "keras-cv 0.9.0 requires keras-core, which is not installed.\n",
      "keras-nlp 0.12.1 requires keras-core, which is not installed.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n",
      "distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n",
      "jupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\n",
      "ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-24.4.2 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-24.1 pathspec-0.12.1 portalocker-2.8.2 pycocotools-2.0.7 yacs-0.1.8\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "!git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:07.616412Z",
     "iopub.status.busy": "2024-06-14T13:11:07.615840Z",
     "iopub.status.idle": "2024-06-14T13:11:08.799857Z",
     "shell.execute_reply": "2024-06-14T13:11:08.798584Z",
     "shell.execute_reply.started": "2024-06-14T13:11:07.616381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "torch:  2.1 ; cuda:  2.1.2\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:08.801661Z",
     "iopub.status.busy": "2024-06-14T13:11:08.801317Z",
     "iopub.status.idle": "2024-06-14T13:11:09.140442Z",
     "shell.execute_reply": "2024-06-14T13:11:09.139653Z",
     "shell.execute_reply.started": "2024-06-14T13:11:08.801631Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:09.142034Z",
     "iopub.status.busy": "2024-06-14T13:11:09.141578Z",
     "iopub.status.idle": "2024-06-14T13:11:09.146559Z",
     "shell.execute_reply": "2024-06-14T13:11:09.145631Z",
     "shell.execute_reply.started": "2024-06-14T13:11:09.142009Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:09.149593Z",
     "iopub.status.busy": "2024-06-14T13:11:09.149302Z",
     "iopub.status.idle": "2024-06-14T13:11:11.215856Z",
     "shell.execute_reply": "2024-06-14T13:11:11.214856Z",
     "shell.execute_reply.started": "2024-06-14T13:11:09.149568Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_train_loader, build_detection_test_loader\n",
    "from detectron2.data import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.217922Z",
     "iopub.status.busy": "2024-06-14T13:11:11.217068Z",
     "iopub.status.idle": "2024-06-14T13:11:11.222991Z",
     "shell.execute_reply": "2024-06-14T13:11:11.221744Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.217893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the mapping from class IDs to class names\n",
    "class_names_dict = {\n",
    "    0: 'pedestrian',\n",
    "    1: 'people',\n",
    "    2: 'bicycle',\n",
    "    3: 'car',\n",
    "    4: 'van',\n",
    "    5: 'truck',\n",
    "    6: 'tricycle',\n",
    "    7: 'awning-tricycle',\n",
    "    8: 'bus',\n",
    "    9: 'motor'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.224338Z",
     "iopub.status.busy": "2024-06-14T13:11:11.224070Z",
     "iopub.status.idle": "2024-06-14T13:11:11.236552Z",
     "shell.execute_reply": "2024-06-14T13:11:11.235743Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.224309Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load dataset annotations\n",
    "def get_visdrone_dicts(img_dir, ann_dir):\n",
    "    dataset_dicts = []\n",
    "    for idx, filename in enumerate(os.listdir(img_dir)):\n",
    "        record = {}\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "        height, width = cv2.imread(img_path).shape[:2]\n",
    "\n",
    "        record[\"file_name\"] = img_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "\n",
    "        ann_file = os.path.join(ann_dir, filename.replace('.jpg', '.txt'))\n",
    "        objs = []\n",
    "\n",
    "        with open(ann_file, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                elements = line.strip().split(',')\n",
    "                x_min, y_min, w, h, class_id = int(elements[0]), int(elements[1]), int(elements[2]), int(elements[3]), int(elements[5]) - 1\n",
    "                if (0 <= class_id <= 9 and w > 0 and h > 0):\n",
    "                    obj = {\n",
    "                        \"bbox\": [x_min, y_min, x_min + w, y_min + h],\n",
    "                        \"bbox_mode\": detectron2.structures.BoxMode.XYXY_ABS,\n",
    "                        \"category_id\": class_id,\n",
    "                    }\n",
    "                    objs.append(obj)\n",
    "        record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.237716Z",
     "iopub.status.busy": "2024-06-14T13:11:11.237449Z",
     "iopub.status.idle": "2024-06-14T13:11:11.250777Z",
     "shell.execute_reply": "2024-06-14T13:11:11.250052Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.237694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths for train, validation, and test datasets\n",
    "image_train_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-train/VisDrone2019-DET-train/images/\"\n",
    "annotation_train_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-train/VisDrone2019-DET-train/annotations/\"\n",
    "\n",
    "image_val_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-val/VisDrone2019-DET-val/images/\"\n",
    "annotation_val_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-val/VisDrone2019-DET-val/annotations/\"\n",
    "\n",
    "image_test_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-test-dev/images/\"\n",
    "annotation_test_folder = \"/kaggle/input/visdrone2019/VisDrone2019-DET-test-dev/annotations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.251992Z",
     "iopub.status.busy": "2024-06-14T13:11:11.251702Z",
     "iopub.status.idle": "2024-06-14T13:11:11.266182Z",
     "shell.execute_reply": "2024-06-14T13:11:11.265234Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.251959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namespace(name='visdrone_test',\n",
       "          thing_classes=['pedestrian',\n",
       "                         'people',\n",
       "                         'bicycle',\n",
       "                         'car',\n",
       "                         'van',\n",
       "                         'truck',\n",
       "                         'tricycle',\n",
       "                         'awning-tricycle',\n",
       "                         'bus',\n",
       "                         'motor'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register datasets\n",
    "DatasetCatalog.register(\"visdrone_train\", lambda: get_visdrone_dicts(image_train_folder, annotation_train_folder))\n",
    "MetadataCatalog.get(\"visdrone_train\").set(thing_classes=list(class_names_dict.values()))\n",
    "\n",
    "DatasetCatalog.register(\"visdrone_val\", lambda: get_visdrone_dicts(image_val_folder, annotation_val_folder))\n",
    "MetadataCatalog.get(\"visdrone_val\").set(thing_classes=list(class_names_dict.values()))\n",
    "\n",
    "DatasetCatalog.register(\"visdrone_test\", lambda: get_visdrone_dicts(image_test_folder, annotation_test_folder))\n",
    "MetadataCatalog.get(\"visdrone_test\").set(thing_classes=list(class_names_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.267678Z",
     "iopub.status.busy": "2024-06-14T13:11:11.267337Z",
     "iopub.status.idle": "2024-06-14T13:11:11.296052Z",
     "shell.execute_reply": "2024-06-14T13:11:11.295199Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.267643Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup configurations for training\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"visdrone_train\",)\n",
    "cfg.DATASETS.TEST = (\"visdrone_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00005\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(class_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.297466Z",
     "iopub.status.busy": "2024-06-14T13:11:11.297211Z",
     "iopub.status.idle": "2024-06-14T13:11:11.303858Z",
     "shell.execute_reply": "2024-06-14T13:11:11.302955Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.297443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Augmentation setup\n",
    "augmentation = [\n",
    "    T.RandomFlip(prob=0.3, horizontal=True, vertical=False),  # Random horizontal flip with 30% probability\n",
    "    T.RandomBrightness(0.9, 1.1),  # Random brightness adjustment\n",
    "    T.RandomContrast(0.8, 1.2),    # Random contrast adjustment\n",
    "    T.RandomSaturation(0.8, 1.2),  # Random saturation adjustment\n",
    "    T.RandomRotation(angle=[0, 90, 180, 270], expand=True),  # Random rotation\n",
    "]\n",
    "\n",
    "# Create the AugmentationList instance\n",
    "augmentation_list = T.AugmentationList(augmentation)\n",
    "\n",
    "# Apply augmentation in the cfg.INPUT as a list\n",
    "cfg.INPUT.AUGMENTATION = augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.305933Z",
     "iopub.status.busy": "2024-06-14T13:11:11.305187Z",
     "iopub.status.idle": "2024-06-14T13:11:11.315355Z",
     "shell.execute_reply": "2024-06-14T13:11:11.314412Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.305908Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.317408Z",
     "iopub.status.busy": "2024-06-14T13:11:11.316578Z",
     "iopub.status.idle": "2024-06-14T13:11:11.326637Z",
     "shell.execute_reply": "2024-06-14T13:11:11.325667Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.317382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a custom DatasetMapper with augmentation\n",
    "class CustomDatasetMapper:\n",
    "    def __init__(self, cfg):\n",
    "        # Dataset augmentation as defined in the cfg.INPUT\n",
    "        self.augmentation = T.AugmentationList(cfg.INPUT.AUGMENTATION)\n",
    "\n",
    "    def __call__(self, dataset_dict):\n",
    "        # Read image and annotations\n",
    "        image = cv2.imread(dataset_dict[\"file_name\"])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        annos = dataset_dict[\"annotations\"]\n",
    "\n",
    "        # Apply augmentation\n",
    "        transforms = self.augmentation(image=image, annotations=annos)\n",
    "        image = transforms[\"image\"]\n",
    "        annos = transforms[\"annotations\"]\n",
    "\n",
    "        # Update dataset_dict with augmented data\n",
    "        dataset_dict[\"image\"] = image\n",
    "        dataset_dict[\"annotations\"] = annos\n",
    "        return dataset_dict\n",
    "\n",
    "# Set custom mapper function for training\n",
    "def mapper_fn_train(dataset_dict):\n",
    "    return CustomDatasetMapper(cfg)(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:11:11.330236Z",
     "iopub.status.busy": "2024-06-14T13:11:11.329569Z",
     "iopub.status.idle": "2024-06-14T13:58:32.485757Z",
     "shell.execute_reply": "2024-06-14T13:58:32.484740Z",
     "shell.execute_reply.started": "2024-06-14T13:11:11.330209Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [00:03, 46.6MB/s]                              \n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "2024-06-14 13:14:46.579999: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-14 13:14:46.580164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-14 13:14:46.714098: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:58:32.488168Z",
     "iopub.status.busy": "2024-06-14T13:58:32.487466Z",
     "iopub.status.idle": "2024-06-14T13:58:32.761782Z",
     "shell.execute_reply": "2024-06-14T13:58:32.760966Z",
     "shell.execute_reply.started": "2024-06-14T13:58:32.488135Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save final model weights\n",
    "model_weights_path = os.path.join(\"/kaggle/working/output\", \"visdrone2019_detectron2.pth\")\n",
    "torch.save(trainer.model.state_dict(), model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T13:58:32.763630Z",
     "iopub.status.busy": "2024-06-14T13:58:32.763179Z",
     "iopub.status.idle": "2024-06-14T14:03:10.553451Z",
     "shell.execute_reply": "2024-06-14T14:03:10.552472Z",
     "shell.execute_reply.started": "2024-06-14T13:58:32.763596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.74s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=86.85s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.98s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.178\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.099\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.158\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.145\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.096\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.281\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n",
      "OrderedDict([('bbox', {'AP': 9.800001381535811, 'AP50': 17.84668250847348, 'AP75': 9.866983597623257, 'APs': 4.305673678317112, 'APm': 15.805043203566726, 'APl': 25.022591287211654, 'AP-pedestrian': 9.271806862186237, 'AP-people': 2.4526135126619772, 'AP-bicycle': 1.046872175792148, 'AP-car': 34.44434134766935, 'AP-van': 11.628751240252566, 'AP-truck': 8.183141593941787, 'AP-tricycle': 2.4233795631900796, 'AP-awning-tricycle': 0.0, 'AP-bus': 24.4060106630296, 'AP-motor': 4.14309685663436})])\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "evaluator = COCOEvaluator(\"visdrone_test\", cfg, False, output_dir=\"./output/\")\n",
    "test_loader = build_detection_test_loader(cfg, \"visdrone_test\")\n",
    "print(inference_on_dataset(trainer.model, test_loader, evaluator))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5048731,
     "sourceId": 8467813,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
